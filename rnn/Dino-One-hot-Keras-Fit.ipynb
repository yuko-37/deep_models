{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0985b0ab-1d83-475a-afdd-33cf5e195c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "# print(tf.__version__)\n",
    "# print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df47c3b7-7d42-453c-bd7d-60e3ee45e778",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e246bb-23a0-43aa-96b5-7943ebb5b850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabular [27 chars]: ['\\n', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "maxlen = 26, dino=lisboasaurusliubangosaurus, idx = 791\n",
      "\n",
      "char_to_ix = {'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "\n",
      "ix_to_char = {0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
      "\n",
      "len(inputs) = 1536, len(outputs) = 1536\n",
      "\n",
      "inputs[200] = [None, 2, 9, 5, 14, 15, 19, 1, 21, 18, 21, 19]\n",
      "outputs[200] = [2, 9, 5, 14, 15, 19, 1, 21, 18, 21, 19, 0]\n",
      "\n",
      "X_padded.shape = (1536, 27, 27)\n",
      "Y_padded.shape = (1536, 27, 27)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"dinos.txt\", \"r\") as f:\n",
    "    dinos_str = f.read().lower()\n",
    "\n",
    "vocabular = sorted(set(dinos_str))\n",
    "print(f\"Vocabular [{len(vocabular)} chars]: {vocabular}\\n\")\n",
    "\n",
    "dinos = [ds.strip() for ds in dinos_str.split(\"\\n\")]\n",
    "lens = [(len(d), d) for d in dinos]\n",
    "maxlen, d = max(lens)\n",
    "maxidx = lens.index((maxlen, d))\n",
    "print(f\"maxlen = {maxlen}, dino={d}, idx = {maxidx}\\n\")\n",
    "\n",
    "char_to_ix = { ch:i for i,ch in enumerate(vocabular) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(vocabular) }\n",
    "\n",
    "print(f\"char_to_ix = {char_to_ix}\\n\")\n",
    "print(f\"ix_to_char = {ix_to_char}\\n\")\n",
    "\n",
    "n_vocab_size = 27 # 26 lower english letters + \\n\n",
    "n_a = 50 # number of state units\n",
    "\n",
    "inputs = [[None] + [char_to_ix[char] for char in dino] for dino in dinos]\n",
    "outputs = [x[1:] + [0] for x in inputs]\n",
    "print(f\"len(inputs) = {len(inputs)}, len(outputs) = {len(outputs)}\\n\")\n",
    "print(f\"inputs[200] = {inputs[200]}\")\n",
    "print(f\"outputs[200] = {outputs[200]}\\n\")\n",
    "\n",
    "\n",
    "def indexes_to_one_hot_vectors(inputs, ohv_dim):\n",
    "    vectors = []\n",
    "    for item in inputs:\n",
    "        vector = np.zeros((len(item), ohv_dim))\n",
    "        \n",
    "        for i, idx in enumerate(item):\n",
    "            if idx is None:\n",
    "                vector[i] = [0] * ohv_dim\n",
    "            else:\n",
    "                vector[i][idx] = 1\n",
    "\n",
    "        vectors.append(vector)\n",
    "        \n",
    "    return vectors\n",
    "\n",
    "\n",
    "x_sequences = indexes_to_one_hot_vectors(inputs, n_vocab_size)\n",
    "y_sequences = indexes_to_one_hot_vectors(outputs, n_vocab_size)\n",
    "\n",
    "X_padded = tf.keras.utils.pad_sequences(x_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "Y_padded = tf.keras.utils.pad_sequences(y_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "\n",
    "print(f\"X_padded.shape = {X_padded.shape}\")\n",
    "print(f\"Y_padded.shape = {Y_padded.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01b7d2-0e1f-4a6b-8a7d-262db5258b2e",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5884579-3db9-4a3d-b087-4c4e7e52d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(model, newline_char=0, max_len=27):\n",
    "    counter = 0\n",
    "    indices = []\n",
    "    x = np.zeros((1, n_vocab_size))\n",
    "    idx = -1\n",
    "    state = None\n",
    "    \n",
    "    while idx != newline_char and counter < max_len:\n",
    "        y_pred = model.predict(np.expand_dims(x, axis=0), verbose=0)\n",
    "        probs = y_pred[0, -1, :]\n",
    "        idx = np.random.choice(range(len(probs)), p=probs)\n",
    "        if idx == 0:\n",
    "            break\n",
    "        indices.append(idx)\n",
    "        new_x = np.zeros((n_vocab_size,))\n",
    "        new_x[idx] = 1.0\n",
    "        x = np.vstack([x, new_x])\n",
    "        counter+=1\n",
    "    \n",
    "    return indices\n",
    "\n",
    "\n",
    "def get_sample(model):\n",
    "    indices = sample_sequence(model)\n",
    "    name = \"\".join([ix_to_char[i] for i in indices])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e528b-2b7f-4755-9d8a-5f80f78b529a",
   "metadata": {},
   "source": [
    "# Model RNN & fit() with SGD on padded X, Y with SmoothEpochCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f10d22-306e-412f-8d57-74674acf99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothLossEpochCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, alpha=0.001):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.smooth_loss = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if self.smooth_loss is None:\n",
    "                self.smooth_loss = loss\n",
    "            else:\n",
    "                self.smooth_loss = self.smooth_loss * (1 - self.alpha) + loss * self.alpha\n",
    "            \n",
    "            print(f\"\\n\\nEpoch {epoch}: loss={loss:.4f}, smooth_loss={self.smooth_loss:.4f}\\n\")\n",
    "    \n",
    "\n",
    "X = tf.keras.utils.pad_sequences(x_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "Y = tf.keras.utils.pad_sequences(y_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "\n",
    "print(f\"type(X) = {type(X)}, len(X) = {len(X)}\")\n",
    "print(f\"type(Y) = {type(Y)}, len(Y) = {len(Y)}\")\n",
    "\n",
    "kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "recurrent_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "bias_initializer=tf.keras.initializers.Ones() \n",
    "\n",
    "inp = tf.keras.Input(shape=(None, n_vocab_size))\n",
    "x = tfl.Masking(mask_value=-1.)(inp)\n",
    "rnn_cell = tfl.SimpleRNNCell(\n",
    "    n_a,\n",
    "    kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "    recurrent_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Ones()\n",
    ")\n",
    "x = tfl.RNN(rnn_cell, return_sequences=True) (x)\n",
    "out = tfl.Dense(n_vocab_size, activation=\"softmax\",\n",
    "                    kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "                    bias_initializer=tf.keras.initializers.Ones())(x)\n",
    "lstm_model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, clipvalue=5.0)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM)\n",
    "lstm_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "lstm_model.save(\"New-dino_RNN_SGD_Fit_15_epochs.keras\")\n",
    "\n",
    "history = lstm_model.fit(X, Y, batch_size=1, epochs=1, callbacks=[SmoothLossEpochCallback(alpha=0.001)])\n",
    "print(\"\\n\\n\")\n",
    "# plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f730aa-841b-4597-b4e1-b67af84eb4f4",
   "metadata": {},
   "source": [
    "## Sampling with Model RNN & fit() with SGD on padded X, Y with SmoothEpochCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe3e91a-1eff-4194-a15a-43e55c1581d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = Arpuropherator, len = 14\n",
      "name = Tenarasaurus, len = 12\n",
      "name = Rabanosaurus, len = 12\n",
      "name = Qabtertitatodon, len = 15\n",
      "name = Yontaorasaurus, len = 14\n",
      "name = Qunluyalianhuriodon, len = 19\n",
      "name = Aegnyrosniulonolus, len = 18\n",
      "name = Zapernesaurus, len = 13\n",
      "name = Telaedathallertatus, len = 19\n",
      "name = Limuriangorosaurus, len = 18\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"dino_RNN_SGD_Fit_15_epochs.keras\")\n",
    "\n",
    "for _ in range(10):\n",
    "    name = get_sample(loaded_model)\n",
    "    print(f\"name = {name.title()}, len = {len(name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3fc2db-592d-45f9-81d9-9c52798cba54",
   "metadata": {},
   "source": [
    "# Model RNN & Batch fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cbead9-298d-4323-9699-ff5090221c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X) = <class 'numpy.ndarray'>, len(X) = 1536\n",
      "type(Y) = <class 'numpy.ndarray'>, len(Y) = 1536\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 23:43:37.205322: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2025-12-08 23:43:37.205372: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-12-08 23:43:37.205381: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-12-08 23:43:37.205406: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-12-08 23:43:37.205423: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-12-08 23:43:37.507255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - accuracy: 0.1969 - loss: 2.7143\n",
      "Epoch 2/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - accuracy: 0.3788 - loss: 2.1176\n",
      "Epoch 3/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 198ms/step - accuracy: 0.4238 - loss: 1.9043\n",
      "Epoch 4/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 196ms/step - accuracy: 0.4469 - loss: 1.8273\n",
      "Epoch 5/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - accuracy: 0.4657 - loss: 1.7770\n",
      "Epoch 6/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 196ms/step - accuracy: 0.4779 - loss: 1.7386\n",
      "Epoch 7/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 197ms/step - accuracy: 0.4886 - loss: 1.7027\n",
      "Epoch 8/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 195ms/step - accuracy: 0.4969 - loss: 1.6759\n",
      "Epoch 9/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - accuracy: 0.5022 - loss: 1.6520\n",
      "Epoch 10/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - accuracy: 0.5094 - loss: 1.6374\n",
      "Epoch 11/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - accuracy: 0.5163 - loss: 1.6162\n",
      "Epoch 12/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - accuracy: 0.5170 - loss: 1.6018\n",
      "Epoch 13/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - accuracy: 0.5193 - loss: 1.5924\n",
      "Epoch 14/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - accuracy: 0.5238 - loss: 1.5781\n",
      "Epoch 15/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - accuracy: 0.5281 - loss: 1.5656\n"
     ]
    }
   ],
   "source": [
    "# class SamplingLossEpochCallback(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         print(\"\\n\\nGenerated names:\")\n",
    "#         for _ in range(7):\n",
    "#             name = get_sample(self.model)\n",
    "#             print(f\"\\t{name.title()}\")\n",
    "\n",
    "\n",
    "X = tf.keras.utils.pad_sequences(x_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "Y = tf.keras.utils.pad_sequences(y_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "\n",
    "print(f\"type(X) = {type(X)}, len(X) = {len(X)}\")\n",
    "print(f\"type(Y) = {type(Y)}, len(Y) = {len(Y)}\")\n",
    "\n",
    "kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "recurrent_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "bias_initializer=tf.keras.initializers.Ones() \n",
    "\n",
    "inp = tf.keras.Input(shape=(None, n_vocab_size))\n",
    "x = tfl.Masking(mask_value=-1.)(inp)\n",
    "rnn_cell = tfl.SimpleRNNCell(\n",
    "    n_a,\n",
    "    kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "    recurrent_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Ones()\n",
    ")\n",
    "x = tfl.RNN(rnn_cell, return_sequences=True) (x)\n",
    "out = tfl.Dense(n_vocab_size, activation=\"softmax\",\n",
    "                    kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "                    bias_initializer=tf.keras.initializers.Ones())(x)\n",
    "rnn_model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, clipvalue=5.0)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "rnn_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# rnn_model.summary()\n",
    "\n",
    "history = rnn_model.fit(X, Y, batch_size=32, epochs=15)\n",
    "rnn_model.save(\"DELETE-dino_RNN_Batch_Fit_15_epochs.keras\")\n",
    "\n",
    "# plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f948514-332a-4fa3-b43d-4955e7dccfa2",
   "metadata": {},
   "source": [
    "## Samping with RNN Batch fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79d0d6e-1ed6-40fb-b40c-0e1fe801b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = Shinyungosaurus, len = 15\n",
      "name = Nionthuenisaurus, len = 16\n",
      "name = Jiavetterapteryx, len = 16\n",
      "name = Sagonusaurus, len = 12\n",
      "name = Tysmonorax, len = 10\n",
      "name = Alchelera, len = 9\n",
      "name = Ruriensaurus, len = 12\n",
      "name = Chetrasaurus, len = 12\n",
      "name = Scramamiavimus, len = 14\n",
      "name = Viantastrops, len = 12\n"
     ]
    }
   ],
   "source": [
    "batch_model = tf.keras.models.load_model(\"DELETE-dino_RNN_Batch_Fit_15_epochs.keras\")\n",
    "\n",
    "for _ in range(10):\n",
    "    name = get_sample(batch_model)\n",
    "    print(f\"name = {name.title()}, len = {len(name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292230ff-a667-4e8c-8991-e39f2c0c5351",
   "metadata": {},
   "source": [
    "# Model LSTM Masking Batch & fit() on padded X, Y with SamplingEpochCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1373261d-5074-4a88-af19-eb6fe1507db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 27, 27)\n",
      "(1536, 27, 27)\n",
      "Epoch 1/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1874 - loss: 2.8124\n",
      "\n",
      "Generated names:\n",
      "\tHnrueusud\n",
      "\tAnjleoolrhtl\n",
      "\tItihonhaurus\n",
      "\tPororasauyrto\n",
      "\tNaycedototonuo\n",
      "\tRotauradocous\n",
      "\tCtepitoos\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.2575 - loss: 2.5743\n",
      "Epoch 2/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3973 - loss: 2.0928\n",
      "\n",
      "Generated names:\n",
      "\tGiberasaerus\n",
      "\tUrusaus\n",
      "\tArlysaurus\n",
      "\tOnnitilhtoretoop\n",
      "\tHniydosaurus\n",
      "\tQabontaiatoru\n",
      "\tBiwmasaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4079 - loss: 2.0255\n",
      "Epoch 3/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4440 - loss: 1.8649\n",
      "\n",
      "Generated names:\n",
      "\tYglhiotera\n",
      "\tSrialonus\n",
      "\tDyzngopetos\n",
      "\tJaceliaxetes\n",
      "\tAnhaleposaurus\n",
      "\tJwakocroria\n",
      "\tAnlphientalus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.4481 - loss: 1.8596\n",
      "Epoch 4/15\n",
      "\u001b[1m45/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4616 - loss: 1.8056\n",
      "\n",
      "Generated names:\n",
      "\tGsucerokosaurus\n",
      "\tNoiganapeupkonbanx\n",
      "\tIdronosaurus\n",
      "\tEnfsisaureg\n",
      "\tDinghaloptor\n",
      "\tXtilosaurus\n",
      "\tRenohyptaplyminus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.4708 - loss: 1.7789\n",
      "Epoch 5/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4830 - loss: 1.7377\n",
      "\n",
      "Generated names:\n",
      "\tLeopenosaurus\n",
      "\tMauungsaurus\n",
      "\tChanosaurus\n",
      "\tPelosaurus\n",
      "\tUetsaoratos\n",
      "\tHyofosaurus\n",
      "\tZosqniasaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.4896 - loss: 1.7165\n",
      "Epoch 6/15\n",
      "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4994 - loss: 1.6670\n",
      "\n",
      "Generated names:\n",
      "\tUstrosaurus\n",
      "\tMangehodon\n",
      "\tLaperocachilosim\n",
      "\t\n",
      "\tLatravematus\n",
      "\tNauramamisaurus\n",
      "\tJurasaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5005 - loss: 1.6684\n",
      "Epoch 7/15\n",
      "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5160 - loss: 1.6188\n",
      "\n",
      "Generated names:\n",
      "\tVelcelaptor\n",
      "\tTatonisaura\n",
      "\tHiguasaurus\n",
      "\tSironikaisaurus\n",
      "\tCpalmalognyx\n",
      "\tBiehosinus\n",
      "\tAdoptosaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5167 - loss: 1.6196\n",
      "Epoch 8/15\n",
      "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5218 - loss: 1.5875\n",
      "\n",
      "Generated names:\n",
      "\tCryeptos\n",
      "\tChigicendos\n",
      "\tJixabgotia\n",
      "\tHeceopoesaurus\n",
      "\tMuaxiasaurus\n",
      "\tLapator\n",
      "\tNychodon\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5251 - loss: 1.5827\n",
      "Epoch 9/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5385 - loss: 1.5418\n",
      "\n",
      "Generated names:\n",
      "\tPrypusaurus\n",
      "\tBryandoraps\n",
      "\tBrikkolesaurus\n",
      "\tCinongosaura\n",
      "\tDiwangbin\n",
      "\tPimognatophasaura\n",
      "\tPeluoraptor\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.5349 - loss: 1.5521\n",
      "Epoch 10/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5429 - loss: 1.5277\n",
      "\n",
      "Generated names:\n",
      "\tChyruitrosaurus\n",
      "\tHeigonoceratops\n",
      "\tRaypyrus\n",
      "\tUracheuria\n",
      "\tAntorodontu\n",
      "\tSticrojonmaus\n",
      "\tMampeltosphus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5422 - loss: 1.5232\n",
      "Epoch 11/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5492 - loss: 1.4933\n",
      "\n",
      "Generated names:\n",
      "\tSpacoreor\n",
      "\tGuesaurus\n",
      "\tEodramestus\n",
      "\tYunoceratops\n",
      "\tEudasaurus\n",
      "\tIskrroeus\n",
      "\tAmarbiocephodo\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5499 - loss: 1.4955\n",
      "Epoch 12/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5600 - loss: 1.4686\n",
      "\n",
      "Generated names:\n",
      "\tDahwalia\n",
      "\tUditelong\n",
      "\tCkilwisaurus\n",
      "\tGartpondosaurus\n",
      "\tStitakosaurus\n",
      "\tNeoberradroces\n",
      "\tAhisthoraptor\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.5577 - loss: 1.4692\n",
      "Epoch 13/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5638 - loss: 1.4371\n",
      "\n",
      "Generated names:\n",
      "\tRrhypimosaurus\n",
      "\tRahaisaurus\n",
      "\tMalatunsaurus\n",
      "\tLu\n",
      "\tGalognatholeus\n",
      "\tHoleniucho\n",
      "\tElueosaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5625 - loss: 1.4420\n",
      "Epoch 14/15\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5725 - loss: 1.4113\n",
      "\n",
      "Generated names:\n",
      "\tDovicoraptor\n",
      "\tHyppessaurus\n",
      "\tIceonosaurus\n",
      "\tBoselilarnia\n",
      "\tHuwullognathus\n",
      "\tRacapsaus\n",
      "\tDrepuevurnitiamanosaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.5692 - loss: 1.4193\n",
      "Epoch 15/15\n",
      "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5786 - loss: 1.3971\n",
      "\n",
      "Generated names:\n",
      "\tTitarospondenosaurus\n",
      "\tInoraptor\n",
      "\tPartentarus\n",
      "\tVendimimus\n",
      "\tAmpalosaurus\n",
      "\tTaraga\n",
      "\tPanoceratops\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.5757 - loss: 1.3949\n"
     ]
    }
   ],
   "source": [
    "class SamplingLossEpochCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"\\n\\nGenerated names:\")\n",
    "        for _ in range(7):\n",
    "            name = get_sample(self.model)\n",
    "            print(f\"\\t{name.title()}\")\n",
    "\n",
    "\n",
    "X = tf.keras.utils.pad_sequences(x_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "Y = tf.keras.utils.pad_sequences(y_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "inp = tf.keras.Input(shape=(None, n_vocab_size))\n",
    "x = tfl.Masking(mask_value=-1.)(inp)\n",
    "x = tfl.LSTM(n_a, return_sequences=True)(x)\n",
    "out = tfl.Dense(n_vocab_size, activation=\"softmax\")(x)\n",
    "lstm_model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, clipvalue=10.0)\n",
    "lstm_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = lstm_model.fit(X, Y, batch_size=32, epochs=15, callbacks=[SamplingLossEpochCallback()])\n",
    "lstm_model.save(\"dino_LSTM_Batch_Fit.keras\")\n",
    "# plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cbf25-496e-4d71-8a20-44fa54842d8c",
   "metadata": {},
   "source": [
    "## Sampling with LSTM Batch fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17d2cf81-77d7-44ae-a424-e1c4595589c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dreigolosaurus\n",
      "Walzokrimes\n",
      "Mhedoceratops\n",
      "Denosaurus\n",
      "Nolochamelon\n",
      "Baironathus\n",
      "Mikasaria\n"
     ]
    }
   ],
   "source": [
    "loaded = tf.keras.models.load_model(\"dino_LSTM_Batch_Fit.keras\")\n",
    "\n",
    "for i in range(7):\n",
    "    name = get_sample(loaded)\n",
    "    print(name.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949c323-c5d2-4e3c-9e49-02588811aa09",
   "metadata": {},
   "source": [
    "# Loaded Model continue fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ad3556-7b2c-45df-8582-72aace4bad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 27, 27)\n",
      "(1536, 27, 27)\n",
      "Epoch 1/10\n",
      "\u001b[1m45/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6639 - loss: 1.0914\n",
      "\n",
      "Generated names:\n",
      "\tBilaony\n",
      "\tJinutadoviaden\n",
      "\tMorusoliskus\n",
      "\tEukuerr\n",
      "\tMacroceratops\n",
      "\tInima\n",
      "\tColombgasaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6605 - loss: 1.0968\n",
      "Epoch 2/10\n",
      "\u001b[1m43/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6845 - loss: 1.0387\n",
      "\n",
      "Generated names:\n",
      "\tDrocaraphodyn\n",
      "\tShiptosaurus\n",
      "\tOnchuanognathus\n",
      "\tKalas\n",
      "\tShinghyrennosaurus\n",
      "\tProtianognathus\n",
      "\tHetetoraptor\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6726 - loss: 1.0618\n",
      "Epoch 3/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6826 - loss: 1.0401\n",
      "\n",
      "Generated names:\n",
      "\tFulunsaura\n",
      "\tXuaniagnathus\n",
      "\tOrnatosaurus\n",
      "\tJanmensaurus\n",
      "\tSankusaurus\n",
      "\tArkanaria\n",
      "\tTerkhosaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6749 - loss: 1.0562\n",
      "Epoch 4/10\n",
      "\u001b[1m46/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6839 - loss: 1.0198\n",
      "\n",
      "Generated names:\n",
      "\tCampylodon\n",
      "\tOninosaurus\n",
      "\tAltenyzhon\n",
      "\tAndustaur\n",
      "\tXiaosaurus\n",
      "\tAmiasaurus\n",
      "\tDalkisaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6755 - loss: 1.0484\n",
      "Epoch 5/10\n",
      "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6884 - loss: 1.0161\n",
      "\n",
      "Generated names:\n",
      "\tLanag\n",
      "\tGodzlaurentaurus\n",
      "\tTithirosaurus\n",
      "\tPhelodon\n",
      "\tZapania\n",
      "\tSelisana\n",
      "\tTardaceratur\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6795 - loss: 1.0391\n",
      "Epoch 6/10\n",
      "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6813 - loss: 1.0336\n",
      "\n",
      "Generated names:\n",
      "\tMochoconnitos\n",
      "\tDuajurnatia\n",
      "\tTachiosaurus\n",
      "\tTecricon\n",
      "\tWichnnhzus\n",
      "\tOrnitholesoosaurus\n",
      "\tEoceratops\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6787 - loss: 1.0361\n",
      "Epoch 7/10\n",
      "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6850 - loss: 1.0139\n",
      "\n",
      "Generated names:\n",
      "\tAchalosaurus\n",
      "\tOnocheirus\n",
      "\tTitanasaurus\n",
      "\tSelekoceratops\n",
      "\tChilidosaurus\n",
      "\tJegnyptora\n",
      "\tSiamosaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6808 - loss: 1.0311\n",
      "Epoch 8/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6890 - loss: 1.0139\n",
      "\n",
      "Generated names:\n",
      "\tZhongoresmimus\n",
      "\tHysperodrotoscus\n",
      "\tArglorosaurus\n",
      "\tSeimosaurus\n",
      "\tUjiabrapteryx\n",
      "\tColustosaurus\n",
      "\tKergsaura\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6794 - loss: 1.0287\n",
      "Epoch 9/10\n",
      "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6850 - loss: 1.0137\n",
      "\n",
      "Generated names:\n",
      "\tGryphyodesiasia\n",
      "\tEgigunindosaurus\n",
      "\tHonghagalosaurus\n",
      "\tAristatosaurus\n",
      "\tPolyomaurus\n",
      "\tSteumopceratops\n",
      "\tSarchitosaurus\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.6794 - loss: 1.0290\n",
      "Epoch 10/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6878 - loss: 1.0118\n",
      "\n",
      "Generated names:\n",
      "\tFeninasaura\n",
      "\tSiammasaurus\n",
      "\tSauropiasaurus\n",
      "\tBonachenis\n",
      "\tChenthesaurus\n",
      "\tLapsesaurus\n",
      "\tPkoperopel\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6831 - loss: 1.0196\n"
     ]
    }
   ],
   "source": [
    "class SamplingLossEpochCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"\\n\\nGenerated names:\")\n",
    "        for _ in range(7):\n",
    "            name = get_sample(self.model)\n",
    "            print(f\"\\t{name.title()}\")\n",
    "\n",
    "\n",
    "X = tf.keras.utils.pad_sequences(x_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "Y = tf.keras.utils.pad_sequences(y_sequences[:], value=-1.0, padding='post', dtype='float32')\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "loaded_lstm = tf.keras.models.load_model(\"CONTINUED-dino_LSTM_Batch_Fit.keras\")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, clipvalue=10.0)\n",
    "loaded_lstm.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = loaded_lstm.fit(X, Y, batch_size=32, epochs=10, callbacks=[SamplingLossEpochCallback()])\n",
    "loaded_lstm.save(\"CONTINUED-dino_LSTM_Batch_Fit.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead06c02-e223-4bfb-8199-d7e8b98fb055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
